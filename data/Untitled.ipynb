{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
=======
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode character u'\\u7a7f' in position 28: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-158814028dab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m#print(line[30:31])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"#\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mnew_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaption\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unicode-escape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"#\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;31m#print(new_filename)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_filename\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mold_filename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode character u'\\u7a7f' in position 28: ordinal not in range(128)"
>>>>>>> 1b5f436c1453c47d99f439232cbc855efc382473
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "import json\n",
    "from collections import Counter\n",
    "with open(\"flickr8kzh.json\", 'r') as j:\n",
    "    data = json.load(j)\n",
    "max_len=100\n",
    "# Read image paths and captions for each image\n",
    "train_image_paths = []\n",
    "train_image_captions = []\n",
    "val_image_paths = []\n",
    "val_image_captions = []\n",
    "test_image_paths = []\n",
    "test_image_captions = []\n",
    "word_freq = Counter()\n",
    "\n",
    "for img in data['images']:\n",
    "    captions = []\n",
    "    for c in img['sentences']:\n",
    "        # Update word frequency\n",
    "        print(c['tokens'])\n",
    "        word_freq.update(c['tokens'].split(' '))\n",
    "        print(word_freq)\n",
    "        if len(c['tokens']) <= max_len:\n",
    "            captions.append(c['tokens'])"
=======
    "import io\n",
    "import json \n",
    "\n",
    "train_name = 'flickr8kzhbJanbosontrain.txt'\n",
    "train_caption = 'seg.flickr8kzhbJanbosontrain.caption.txt'\n",
    "val_name = 'flickr8kzhbJanbosonval.txt'\n",
    "val_caption = 'seg.flickr8kzhbJanbosonval.caption.txt'\n",
    "test_name = 'flickr8kzhmbosontest.txt'\n",
    "test_caption = 'seg.flickr8kzhmbosontest.caption.txt'\n",
    "\n",
    "dict1 = {} \n",
    "images = []\n",
    "# creating dictionary \n",
    "with io.open(train_caption, 'r') as f: \n",
    "    content = f.readlines()\n",
    "    f.close()\n",
    "    old_filename = \"1000268201_693b08cb0e\"\n",
    "    sentences = []\n",
    "    for line in content: \n",
    "        #print(line[30:31])\n",
    "        if line.find(\"#\")==-1:continue\n",
    "        new_filename, _, caption = line.strip().encode('utf-8').decode(\"unicode-escape\").split(\"#\",2)\n",
    "        #print(new_filename)\n",
    "        if new_filename != old_filename:\n",
    "            #print(\"filename\",old_filename, \"split\",\"train\", \"sentences\",sentences)\n",
    "            images.append({\"filename\":old_filename+\".jpg\", \"split\":\"train\", \"sentences\":sentences})\n",
    "            sentences = []\n",
    "        sentences.append({\"caption_id\":caption[0], \"tokens\":caption[2:]}) \n",
    "        print(sentences)\n",
    "        old_filename = new_filename\n",
    "        if old_filename == \"2709648336_15455e60b2\":\n",
    "            images.append({\"filename\":old_filename+\".jpg\", \"split\":\"train\", \"sentences\":sentences})\n",
    "            \n",
    "            \n",
    "# creating dictionary \n",
    "with io.open(val_caption, 'r') as f: \n",
    "    content = f.readlines()\n",
    "    f.close()\n",
    "    old_filename = \"1022454332_6af2c1449a\"\n",
    "    sentences = []\n",
    "    for line in content: \n",
    "        #print(line[30:31])\n",
    "        if line.find(\"#\")==-1:continue\n",
    "        new_filename, _, caption = line.strip().split(\"#\",2)\n",
    "        #print(new_filename)\n",
    "        if new_filename != old_filename:\n",
    "            #print(\"filename\",old_filename, \"split\",\"train\", \"sentences\",sentences)\n",
    "            images.append({\"filename\":old_filename+\".jpg\", \"split\":\"val\", \"sentences\":sentences})\n",
    "            sentences = []\n",
    "        sentences.append({\"caption_id\":caption[0], \"tokens\":caption[2:]}) \n",
    "        old_filename = new_filename\n",
    "        if old_filename == \"989851184_9ef368e520\":\n",
    "            images.append({\"filename\":old_filename+\".jpg\", \"split\":\"val\", \"sentences\":sentences})\n",
    "            \n",
    "            \n",
    "# creating dictionary \n",
    "with io.open(test_caption, 'r') as f: \n",
    "    content = f.readlines()\n",
    "    f.close()\n",
    "    old_filename = \"1056338697_4f7d7ce270\"\n",
    "    sentences = []\n",
    "    for line in content: \n",
    "        #print(line[30:31])\n",
    "        if line.find(\"#\")==-1:continue\n",
    "        new_filename, _, caption = line.strip().split(\"#\",2)\n",
    "        #print(new_filename)\n",
    "        if new_filename != old_filename:\n",
    "            #print(\"filename\",old_filename, \"split\",\"train\", \"sentences\",sentences)\n",
    "            images.append({\"filename\":old_filename+\".jpg\", \"split\":\"test\", \"sentences\":sentences})\n",
    "            sentences = []\n",
    "        sentences.append({\"caption_id\":caption[0], \"tokens\":str(caption[2:])}) \n",
    "        old_filename = new_filename\n",
    "        if old_filename == \"997722733_0cb5439472\":\n",
    "            images.append({\"filename\":old_filename+\".jpg\", \"split\":\"test\", \"sentences\":sentences})\n",
    "# creating json file \n",
    "# the JSON file is named as test1 \n",
    "print(len(images))\n",
    "dict1[\"images\"] = images\n",
    "out_file = open(\"flickr8kzh.json\", \"w\") \n",
    "json.dump(dict1, out_file, indent = 4, sort_keys = False) \n",
    "out_file.close() \n"
>>>>>>> 1b5f436c1453c47d99f439232cbc855efc382473
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'我': 1, '是': 1, '一个': 1, '小': 1, '姑娘': 1})\n",
      "['我', '是', '一个', '小', '姑娘']\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "word_freq = Counter()\n",
    "text=\"我 是 一个 小 姑娘\"\n",
    "word_freq.update(text.split())\n",
    "print(word_freq)\n",
    "min_word_freq=0\n",
    "words = [w for w in word_freq.keys() if word_freq[w] > min_word_freq]\n",
    "print(words)"
   ]
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
>>>>>>> 1b5f436c1453c47d99f439232cbc855efc382473
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
<<<<<<< HEAD
    "version": 3
=======
    "version": 2
>>>>>>> 1b5f436c1453c47d99f439232cbc855efc382473
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
<<<<<<< HEAD
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
=======
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
>>>>>>> 1b5f436c1453c47d99f439232cbc855efc382473
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
