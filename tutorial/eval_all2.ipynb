{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.version= 1.7.0+cu101\n",
      "device= cuda:1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "from eval import evaluate_with_beam\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "data_folder = '../prepared_data'  # folder with data files saved by create_input_files.py\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")  # sets device for model and PyTorch tensors\n",
    "print(\"torch.version=\", torch.__version__)\n",
    "print(\"device=\",device)\n",
    "cudnn.benchmark = True  # set to true only if inputs to model are fixed size; otherwise lot of computational overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from checkpoints2 import data_names, models, word_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  ../checkpoints/checkpoint_flickr30kzh_5_cap_per_img_5_min_word_freq_seg_based_fine_tune.pth.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EVALUATING AT BEAM SIZE 1: 100%|██████████| 25005/25005 [01:47<00:00, 232.44it/s]\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "for data_name, model, word_map_file in zip(data_names, models, word_maps):\n",
    "\n",
    "    print(\"Model: \", model)\n",
    "    # Load model\n",
    "    checkpoint = torch.load(model, \n",
    "                            #map_location=lambda storage, loc: storage.cuda(1)\n",
    "                           )\n",
    "    decoder = checkpoint['decoder']\n",
    "    decoder = decoder.to(device)\n",
    "    decoder.eval()\n",
    "    encoder = checkpoint['encoder']\n",
    "    encoder = encoder.to(device)\n",
    "    encoder.eval()\n",
    "    # Load word map (word2ix)\n",
    "    with open(word_map_file, 'r') as j:\n",
    "        word_map = json.load(j)\n",
    "    rev_word_map = {v: k for k, v in word_map.items()}\n",
    "    vocab_size = len(word_map)\n",
    "    word_map_start = word_map['<start>']\n",
    "    word_map_end = word_map['<end>']\n",
    "    #print(vocab_size, word_map_start)\n",
    "    # Normalization transform\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "    # Evaluate with beam search\n",
    "    for beam_width in range(1,6):\n",
    "        score = evaluate_with_beam(beam_width, data_name, model, encoder, decoder, word_map, word_map_start, word_map_end, rev_word_map)\n",
    "        print(score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
